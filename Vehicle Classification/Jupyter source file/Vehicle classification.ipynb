{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55313de2-a063-4955-91f6-731769f49a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Load the CSV Dataset\n",
    "csv_path = r\"E:\\Data set\\vehicle dataset\\train\\annotations.csv\"\n",
    "images_dir = r\"E:\\Data set\\vehicle dataset\\train\\images\"\n",
    "\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Step 2: Preprocess the Data\n",
    "# Convert labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, stratify=data['label'])\n",
    "\n",
    "# Function to find the correct image file with multiple extensions\n",
    "def find_image_file(img_name, img_dir):\n",
    "    for ext in ['jpg', 'jpeg', 'png']:\n",
    "        img_path = os.path.join(img_dir, f\"{img_name}.{ext}\")\n",
    "        if os.path.exists(img_path):\n",
    "            return img_path\n",
    "    raise FileNotFoundError(f\"Image file for {img_name} not found with extensions: jpg, jpeg, png\")\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df, img_dir, img_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            # Find the image with supported extensions\n",
    "            img_path = find_image_file(os.path.splitext(row['image'])[0], img_dir)\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)\n",
    "            img = tf.keras.preprocessing.image.img_to_array(img) / 255.0  # Normalize\n",
    "            images.append(img)\n",
    "            labels.append(row['label'])\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)  # Print warning if an image is missing\n",
    "    return tf.convert_to_tensor(images), tf.convert_to_tensor(labels)\n",
    "\n",
    "# Load training and validation images\n",
    "IMG_SIZE = (128, 128)\n",
    "x_train, y_train = load_images(train_data, images_dir, IMG_SIZE)\n",
    "x_val, y_val = load_images(val_data, images_dir, IMG_SIZE)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=len(label_encoder.classes_))\n",
    "y_val = to_categorical(y_val, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Step 3: Define the CNN Model\n",
    "model = Sequential([\n",
    "    # Convolutional layers\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Flatten the feature maps\n",
    "    Flatten(),\n",
    "    \n",
    "    # Fully connected layers\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Step 4: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Data Augmentation for Training\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Step 6: Train the Model\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(\n",
    "    data_gen.flow(x_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 7: Save the Model\n",
    "model.save(r\"E:\\Data set\\vehicle dataset\\train\\vehicle_classification_model.h5\")\n",
    "print(\"Model saved!\")\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "val_loss, val_accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833468a-4aa1-4144-953d-da4be0ec45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 9: Plot Accuracy vs Epoch\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acc22b-8873-4820-bcb7-7f11f4684495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Trained Model\n",
    "model_path = r\"E:\\Data set\\vehicle dataset\\train\\vehicle_classification_model.h5\"\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Step 2: Load Label Encoder to Decode Predictions\n",
    "csv_path = r\"E:\\Data set\\vehicle dataset\\train\\annotations.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])\n",
    "class_names = label_encoder.classes_\n",
    "print(\"Labels loaded successfully!\")\n",
    "\n",
    "# Step 3: Define Image Preprocessing Function\n",
    "def preprocess_image(image_path, img_size=(128, 128)):\n",
    "    img = load_img(image_path, target_size=img_size)\n",
    "    img_array = img_to_array(img) / 255.0  # Normalize\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions for batch\n",
    "    return img, img_array\n",
    "\n",
    "# Step 4: Define Function to Predict Batch of Images\n",
    "def predict_images_in_folder(folder_path):\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        img, img_array = preprocess_image(image_path)\n",
    "        prediction = model.predict(img_array)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        predicted_label = class_names[predicted_class]\n",
    "        confidence = np.max(prediction) * 100\n",
    "        \n",
    "        # Display the image and prediction\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{image_file}\\nPrediction: {predicted_label}\\nConfidence: {confidence:.2f}%\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Image: {image_file}\")\n",
    "        print(f\"Predicted Class: {predicted_label}\")\n",
    "        print(f\"Confidence: {confidence:.2f}%\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Step 5: Test with Images in a Folder\n",
    "test_folder_path = r\"D:\\chandira\\model test\\Test set\\Test set\"  # Change this to your folder path\n",
    "predict_images_in_folder(test_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa731b35-82bf-403c-85d1-d567c7331155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "import serial  \n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load the Trained Model\n",
    "model_path = r\"G:\\Mechatronics\\vehicle dataset\\train\\vehicle_classification_model.h5\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load Label Encoder\n",
    "csv_path = r\"G:\\Mechatronics\\vehicle dataset\\train\\annotations.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# ESP32-CAM Stream URL\n",
    "ESP32_CAM_URL = \"http://192.168.1.4:81/stream\"\n",
    "\n",
    "# Initialize Serial Communication with Arduino\n",
    "arduino = serial.Serial(port=\"COM8\", baudrate=9600, timeout=1)\n",
    "\n",
    "def preprocess_image(frame, img_size=(128, 128)):\n",
    "    img = cv2.resize(frame, img_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "\n",
    "def detect_from_esp32():\n",
    "    try:\n",
    "        stream = requests.get(ESP32_CAM_URL, stream=True, timeout=5)\n",
    "        if stream.status_code != 200:\n",
    "            print(\"Error: Could not connect to ESP32-CAM.\")\n",
    "            return\n",
    "    \n",
    "        bytes_stream = b''\n",
    "        buffer_size_limit = 65536  # Limit buffer size to prevent lag\n",
    "\n",
    "        for chunk in stream.iter_content(chunk_size=1024):\n",
    "            bytes_stream += chunk\n",
    "            if len(bytes_stream) > buffer_size_limit:\n",
    "                bytes_stream = bytes_stream[-buffer_size_limit:]  # Trim buffer\n",
    "\n",
    "            a = bytes_stream.find(b'\\xff\\xd8')  # Start of JPEG\n",
    "            b = bytes_stream.find(b'\\xff\\xd9')  # End of JPEG\n",
    "\n",
    "            if a != -1 and b != -1:\n",
    "                jpg = bytes_stream[a:b+2]\n",
    "                bytes_stream = bytes_stream[b+2:]\n",
    "                \n",
    "                if len(jpg) == 0:\n",
    "                    print(\"Warning: Empty frame received. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                \n",
    "                if frame is None:\n",
    "                    print(\"Warning: Failed to decode frame. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                img_array = preprocess_image(frame)\n",
    "                prediction = model.predict(img_array, verbose=0)\n",
    "                predicted_class = np.argmax(prediction)\n",
    "                predicted_label = class_names[predicted_class]\n",
    "                confidence = np.max(prediction) * 100\n",
    "\n",
    "                # Send detected vehicle type to Arduino\n",
    "                arduino.write(predicted_label.encode() + b'\\n')\n",
    "                print(f\"Detected: {predicted_label}, Confidence: {confidence:.2f}%\")\n",
    "\n",
    "                # Draw bounding box and label\n",
    "                height, width, _ = frame.shape\n",
    "                cv2.rectangle(frame, (50, 50), (width - 50, height - 50), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{predicted_label} ({confidence:.2f}%)\", (60, 90),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow(\"ESP32 Vehicle Detection\", frame)\n",
    "\n",
    "                # Press 'q' to exit\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Network error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    finally:\n",
    "        if arduino.is_open:\n",
    "            arduino.close()\n",
    "\n",
    "# Start Detection from ESP32-CAM\n",
    "detect_from_esp32()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
